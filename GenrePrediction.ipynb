{
    "metadata": {
        "language_info": {
            "name": "python", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "metadata": {}, 
            "source": "<p>\n<img src=\"https://alanattableau.files.wordpress.com/2014/12/cropped-databender4.png\" align=center>\n<h1 align=center>The Last Databenders</h1>\n<h4 align=center>Sponsored By Gutenberg</h4>\n<img src=\"http://www.gutenberg.org/pics/logo-144x144.png\" align=center>\n</p>", 
            "cell_type": "markdown"
        }, 
        {
            "source": "from io import StringIO\nimport requests\nimport json\nimport pandas as pd\nfrom pyspark.sql import Row\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\nfrom pyspark.sql import Row\n\nstopworddd = ['a', \"a's\", 'able', 'about', 'above', 'according',\"project\",\"gutenberg\",\"ebook\",'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', \"c'mon\", \"c's\", 'came', 'can', \"can't\", 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly',\"the\", 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', \"couldn't\", 'course', 'currently', 'd', 'definitely', 'described', 'despite', 'did', \"didn't\", 'different', 'do', 'does', \"doesn't\", 'doing', \"don't\", 'done', 'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'f', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going',\"things\",\"electronic work\",\"electronic\",\"work\",'gone', 'got', 'gotten', 'greetings', 'h', 'had', \"hadn't\", 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he's\", 'hello', 'help', 'hence', 'her', 'here', \"here's\", 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', \"let's\", 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'p', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', \"shouldn't\", 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 't', \"t's\", 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', \"that's\", 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', \"there's\", 'thereafter', 'thereby',\"place\",\"moment\", 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants', 'was', \"wasn't\", 'way', 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'welcome', 'well', 'went', 'were', \"weren't\", 'what', \"what's\", 'whatever', 'when', 'whence', 'whenever', 'where', \"where's\", 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', \"who's\", 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', \"won't\", 'wonder', 'would', 'would', \"wouldn't\", 'x', 'y', 'yes', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', 'z', 'zero',\"made\",\"time\",\"thing\",\"man\",\"hand\",\"men\",\"word\",\"thought\",\"day\",\"electronic work\",\"found\"]\nadjectives = ['able', 'bad', 'best',\"back\", 'better', 'big', 'black', 'certain', 'clear', 'early', 'easy', 'free', 'full', 'good', 'great', 'hard', 'high', 'important', 'large', 'late', 'little', 'local', 'long', 'low', 'major', 'new', 'old', 'only', 'other', 'political', 'possible', 'public', 'real', 'recent', 'right', 'small', 'social', 'special', 'strong', 'sure', 'true', 'white', 'whole', 'young']\ncommon_verbs = ['say', 'make', 'go', 'take', 'come', 'see', 'know', 'get', 'give', 'find', 'think', 'tell', 'become', 'show', 'leave', 'feel', 'put', 'bring', 'begin', 'keep', 'hold', 'write', 'stand', 'hear', 'let', 'mean', 'set', 'meet', 'run', 'pay', 'sit', 'speak', 'lie', 'lead', 'read', 'grow', 'lose', 'fall', 'send', 'build', 'draw', 'break', 'spend', 'cut', 'rise', 'drive', 'buy', 'wear', 'choose', 'said', 'made', 'went', 'took', 'came', 'saw', 'knew', 'got', 'gavefound', 'thought', 'told', 'became', 'showed', 'left', 'felt', 'put', 'brought', 'began', 'kept', 'held', 'wrote', 'stood', 'heard', 'let', 'meant', 'set', 'met', 'ran', 'paid', 'sat', 'spoke', 'lay', 'led', 'read', 'grew', 'lost', 'fell', 'sent', 'built', 'drew', 'broke', 'spent', 'cut', 'rose', 'drove', 'bought', 'wore', 'chose', 'gone', 'taken', 'seen', 'known', 'given', 'shown', 'written', 'spoken', 'lain', 'grown', 'fallen', 'drawn', 'broken', 'risen', 'driven', 'worn', 'chosen', 'wanted', 'used', 'worked', 'called', 'tried', 'asked', 'needed', 'seemed', 'helped', 'played', 'moved', 'lived', 'believed', 'happened', 'included', 'continued', 'changed', 'watched', 'followed', 'stopped', 'created', 'opened', 'walked', 'offered', 'remembered', 'appeared', 'served', 'died', 'stayed', 'reached', 'killed', 'raised', 'passed', 'decided', 'returned', 'explained', 'hoped', 'carried', 'received', 'agreed', 'covered', 'caused', 'closed', 'increased', 'reduced', 'noted', 'entered', 'shared', 'saved', 'protected', 'occurred', 'accepted', 'determined', 'prepared', 'argued', 'recognized', 'indicated', 'arrived', 'answered', 'compared', 'acted', 'studied', 'removed', 'sounded', 'formed', 'visited', 'avoided', 'imagined', 'finished', 'responded', 'maintained', 'contained', 'applied', 'treated', 'affected', 'worried', 'mentioned', 'improved', 'signed', 'existed', 'noticed', 'travelled', 'prevented', 'admitted', 'suffered', 'published', 'counted', 'achieved', 'announced', 'touched', 'attended', 'defined', 'introduced']\nstopwords = stopworddd + adjectives + common_verbs", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 16, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "def get_object_storage_file_with_credentials_9178c0c603054adab28f2ffa6291055a(container, filename):\n    \"\"\"This functions returns a StringIO object containing\n    the file content from Bluemix Object Storage.\"\"\"\n\n    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': 'member_f70040bf9b08b99e0d9f8de4896f080ec4d6a6a5','domain': {'id': 'dae6eace16224226bb3816b040f2b308'},\n            'password': 'qK0sJ#In6XypcB&v'}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2)\n    return StringIO(resp2.text)\n\ndef SetTestFile(fileName):\n    data_1 = get_object_storage_file_with_credentials_9178c0c603054adab28f2ffa6291055a('TheLastDatabendersCS340', '%s' % (fileName))\n    allText = \"\"\n    fl = data_1.read().split(\"\\n\")\n    for line in fl:\n        allText += line + \" \"\n    rd = sc.parallelize([allText])\n    row = Row(\"text\")\n    test = rd.map(row).toDF()\n    return test\n\ndef TrainData(genre, rddFile):\n    interim = rddFile.map(lambda line: (1.0 if line.split(\"\\t\")[0] == genre else 0.0, line.split(\"\\t\")[1]))\n    interim = interim.map(lambda t: Row(label=t[0], text=t[1]))\n    training = sqlContext.createDataFrame(interim)\n    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"word\")\n    stopwordremover = StopWordsRemover(inputCol=\"word\", outputCol=\"words\", stopWords=stopwords)\n    hashingTF = HashingTF(inputCol=stopwordremover.getOutputCol(), outputCol=\"features\")\n    lr = LogisticRegression(maxIter=10, regParam=0.01)\n    pipeline = Pipeline(stages=[tokenizer, stopwordremover, hashingTF, lr])\n    model = pipeline.fit(training)\n    return model\n\ndef CreateAllFiles():\n    categories = ['Adventure', 'History', 'Fantasy',\"Classic\",  \"Children\", 'Horror', 'Romance', 'Science-fiction']\n    taken = []\n    for i in categories:\n        for j in categories:\n            if i != j and (j,i) not in taken:\n                textFile = open(\"%s_%s.txt\" % (i, j), \"w\")\n                file1 = open(\"%s_b.txt\" % (i), \"r\")\n                file2 = open(\"%s_b.txt\" % (j), \"r\")\n                for word in file1:\n                    textFile.write(word)\n                for word in file2:\n                    textFile.write(word)\n                taken.append((i,j))\n                \ndef Predict(testFile):\n    categories = ['Adventure', 'History', 'Fantasy', 'Classic',  \"Children\", 'Horror', 'Romance', 'Science-fiction']\n    second_phase = []\n    # first phase\n    for i in range(0, len(categories), 2):\n        cat1 = categories[i]\n        cat2 = categories[i+1]\n        print cat1,\" vs \", cat2,\n        try:\n            textFile = open(\"%s_%s.txt\" % (cat1, cat2), \"r\")\n        except:\n            try:\n                textFile = open(\"%s_%s.txt\" % (cat2, cat1), \"r\")\n            except:\n                print \"ERROR\"\n                pass\n        rddFile = sc.textFile(\"%s_%s.txt\" % (cat1, cat2))\n        rddFile.persist()\n        model = TrainData(cat1, rddFile)\n        prediction = model.transform(testFile)\n        cat1_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n        cat1_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n        model = TrainData(cat2, rddFile)\n        prediction = model.transform(testFile)\n        cat2_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n        cat2_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n        if cat1_prediction == 1:\n            second_phase.append(cat1)\n            print \">\", cat1\n        elif cat2_prediction == 1:\n            second_phase.append(cat2)\n            print \">\", cat2\n        elif cat1_probability > cat2_probability:\n            second_phase.append(cat1)\n            print \">\", cat1\n        else:\n            second_phase.append(cat2)\n            print \">\", cat2\n\n    print second_phase\n    third_phase = []\n    for i in range(0, len(second_phase), 2):\n        cat1 = second_phase[i]\n        cat2 = second_phase[i+1]\n        print cat1,\" vs \",cat2,\n        try:\n            textFile = open(\"%s_%s.txt\" % (cat1, cat2), \"r\")\n        except:\n            try:\n                textFile = open(\"%s_%s.txt\" % (cat2, cat1), \"r\")\n            except:\n                print \"ERROR\"\n                pass\n        rddFile = sc.textFile(\"%s_%s.txt\" % (cat1, cat2))\n        rddFile.persist()\n        model = TrainData(cat1, rddFile)\n        prediction = model.transform(testFile)\n        cat1_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n        cat1_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n        model = TrainData(cat2, rddFile)\n        prediction = model.transform(testFile)\n        cat2_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n        cat2_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n        if cat1_prediction == 1:\n            third_phase.append(cat1)\n            print \">\", cat1\n        elif cat2_prediction == 1:\n            third_phase.append(cat2)\n            print \">\", cat2\n        elif cat1_probability > cat2_probability:\n            third_phase.append(cat1)\n            print \">\", cat1\n        else:\n            third_phase.append(cat2)\n            print \">\", cat2\n\n    print third_phase\n\n    cat1 = third_phase[0]\n    cat2 = third_phase[1]\n    print cat1,\" vs \", cat2\n    try:\n        textFile = open(\"%s_%s.txt\" % (cat1, cat2), \"r\")\n    except:\n        try:\n            textFile = open(\"%s_%s.txt\" % (cat2, cat1), \"r\")\n        except:\n            print \"ERROR\"\n            pass\n    rddFile = sc.textFile(\"%s_%s.txt\" % (cat1, cat2))\n    rddFile.persist()\n    model = TrainData(cat1, rddFile)\n    prediction = model.transform(testFile)\n    cat1_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n    cat1_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n    model = TrainData(cat2, rddFile)\n    prediction = model.transform(testFile)\n    cat2_prediction = prediction.select(\"prediction\").rdd.map(tuple).collect()[0]\n    cat2_probability = prediction.select(\"probability\").rdd.map(tuple).collect()[0]\n\n    if cat1_prediction == 1:\n        return cat1\n    elif cat2_prediction == 1:\n        return cat2\n    elif cat1_probability > cat2_probability:\n        return cat1\n    else:\n        return cat2", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 25, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "CreateAllFiles()", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": 18, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "source": "testFile = SetTestFile(\"adventureBook.txt\")\nprint Predict(testFile)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Adventure History\nFantasy Classic\nChildren Horror\nRomance Science-fiction\n['Adventure', 'Fantasy', 'Children', 'Romance']\nAdventure Fantasy\nChildren Romance\n['Adventure', 'Children']\nAdventure Children\nAdventure\n"
                }
            ]
        }, 
        {
            "source": "testFile = SetTestFile(\"fantasyBook.txt\") # A Little Boy Lost\nprint Predict(testFile)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Adventure  vs  History\nFantasy  vs  Classic\nChildren  vs  Horror\nRomance  vs  Science-fiction\n['Adventure', 'Fantasy', 'Children', 'Science-fiction']\nAdventure  vs  Fantasy\nChildren  vs  Science-fiction\n['Fantasy', 'Children']\nFantasy  vs  Children\nFantasy\n"
                }
            ]
        }, 
        {
            "source": "testFile = SetTestFile(\"romanceBook.txt\") #The Romance of Gilbert Holmes\nprint Predict(testFile)", 
            "metadata": {
                "collapsed": false
            }, 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Adventure  vs  History\nFantasy  vs  Classic\nChildren  vs  Horror\nRomance  vs  Science-fiction\n['Adventure', 'Classic', 'Horror', 'Romance']\nAdventure  vs  Classic\nHorror  vs  Romance\n['Classic', 'Romance']\nClassic  vs  Romance\nRomance\n"
                }
            ]
        }, 
        {
            "source": "testFile = SetTestFile(\"adventureTestBook.txt\") # Alice in the Wonderland\nprint Predict(testFile)", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat_minor": 0
}